import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import io
import re
import plotly.figure_factory as ff
import scipy # Ajout√© pour r√©soudre ImportError avec create_distplot
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# --- Chemins vers vos fichiers de donn√©es ---
# ATTENTION : Ces chemins ont √©t√© mis √† jour pour √™tre RELATIFS.
# Cela signifie que les fichiers Excel/CSV doivent se trouver dans le M√äME dossier
# que ce script Python lorsque vous le d√©ployez (par exemple, sur GitHub pour Streamlit Community Cloud).
DATA_PATHS = {
    "memory": "memory_final_cleaned_clean.xlsx",
    "hitlist_db": "HITLIST_DATABASE_final_cleaned_clean.xlsx",
    "times": "Times_final_cleaned_clean.xlsx",
    "tasktimes": "TASKTIMES_final_cleaned_clean.xlsx",
    "usertcode": "USERTCODE_cleaned.xlsx",
    "performance": "AL_GET_PERFORMANCE_final_cleaned_clean.xlsx",
    "sql_trace_summary": "performance_trace_summary_final_cleaned_clean.xlsx",
    "usr02": "usr02_data.xlsx",
}

# --- Configuration de la page Streamlit ---
st.set_page_config(layout="wide", page_title="Dashboard SAP Complet Multi-Sources")

# --- Fonctions de Nettoyage et Chargement des Donn√©es (avec cache) ---

def clean_string_column(series, default_value="Non d√©fini"):
    """
    Nettoyage d'une s√©rie de type string : supprime espaces, remplace NaN/vides/caract√®res non imprimables.
    """
    cleaned_series = series.astype(str).str.strip()
    cleaned_series = cleaned_series.apply(lambda x: re.sub(r'[^\x20-\x7E\s]+', ' ', x).strip())
    cleaned_series = cleaned_series.replace({'nan': default_value, '': default_value, ' ': default_value})
    return cleaned_series

def clean_column_names(df):
    """
    Nettoyage des noms de colonnes : supprime les espaces, les caract√®res invisibles,
    et s'assure qu'ils sont valides pour l'acc√®s.
    """
    new_columns = []
    for col in df.columns:
        cleaned_col = re.sub(r'[\x00-\x1F\x7F-\x9F]', '', str(col)).strip()
        cleaned_col = re.sub(r'[^a-zA-Z0-9_]', '_', cleaned_col)
        cleaned_col = re.sub(r'_+', '_', cleaned_col)
        cleaned_col = cleaned_col.strip('_')
        new_columns.append(cleaned_col)
    df.columns = new_columns
    return df

def convert_mm_ss_to_seconds(time_str):
    """
    Convertit une cha√Æne de caract√®res au format MM:SS en secondes.
    G√®re les cas o√π les minutes ou secondes sont manquantes ou invalides.
    """
    if pd.isna(time_str) or not isinstance(time_str, str):
        return 0
    try:
        parts = time_str.split(':')
        if len(parts) == 2:
            minutes = float(parts[0])
            seconds = float(parts[1])
            return int(minutes * 60 + seconds)
        elif len(parts) == 1:
            return int(float(parts[0]))
        else:
            return 0
    except ValueError:
        return 0

def clean_numeric_with_comma(series):
    """
    Nettoyage d'une s√©rie de cha√Ænes num√©riques qui peuvent contenir des virgules
    comme s√©parateurs de milliers ou d√©cimaux, et conversion en float.
    """
    cleaned_series = series.astype(str).str.replace(' ', '').str.replace('.', '', regex=False).str.replace(',', '.', regex=False)
    return pd.to_numeric(cleaned_series, errors='coerce').fillna(0)


@st.cache_data
def load_and_process_data(file_key, path):
    """Charge et nettoie un fichier Excel/CSV."""
    df = pd.DataFrame()
    try:
        if path.lower().endswith('.xlsx'):
            df = pd.read_excel(path)
        elif path.lower().endswith('.csv'):
            df = pd.read_csv(path)
        else:
            st.error(f"Format de fichier non support√© pour {file_key}: {path}")
            return pd.DataFrame()

        df = clean_column_names(df.copy())

        # --- Gestion sp√©cifique des types de donn√©es et valeurs manquantes ---
        if file_key == "memory":
            numeric_cols = ['MEMSUM', 'PRIVSUM', 'USEDBYTES', 'MAXBYTES', 'MAXBYTESDI', 'PRIVCOUNT', 'RESTCOUNT', 'COUNTER']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float)
            
            if 'ACCOUNT' in df.columns:
                df['ACCOUNT'] = clean_string_column(df['ACCOUNT'], 'Compte Inconnu')
            if 'MANDT' in df.columns:
                df['MANDT'] = clean_string_column(df['MANDT'], 'MANDT Inconnu')
            # TASKTYPE removal: Removed df['TASKTYPE'] = clean_string_column(df['TASKTYPE'], 'Type de T√¢che Inconnu')

            if 'ENDDATE' in df.columns and 'ENDTIME' in df.columns:
                df['ENDTIME_STR'] = df['ENDTIME'].astype(str).str.zfill(6)
                df['FULL_DATETIME'] = pd.to_datetime(df['ENDDATE'].astype(str) + df['ENDTIME_STR'], format='%Y%m%d%H%M%S', errors='coerce')
                df.drop(columns=['ENDTIME_STR'], inplace=True, errors='ignore')
            elif 'FULL_DATETIME' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['FULL_DATETIME']):
                df['FULL_DATETIME'] = pd.to_datetime(df['FULL_DATETIME'], errors='coerce')
            
            subset_cols_memory = []
            if 'USEDBYTES' in df.columns:
                subset_cols_memory.append('USEDBYTES')
            if 'ACCOUNT' in df.columns:
                subset_cols_memory.append('ACCOUNT')
            if subset_cols_memory:
                df.dropna(subset=subset_cols_memory, inplace=True)


        elif file_key == "hitlist_db":
            numeric_cols = [
                'GENERATETI', 'REPLOADTI', 'CUALOADTI', 'DYNPLOADTI', 'QUETI', 'DDICTI', 'CPICTI',
                'LOCKCNT', 'LOCKTI', 'BTCSTEPNR', 'RESPTI', 'PROCTI', 'CPUTI', 'QUEUETI', 'ROLLWAITTI',
                'GUITIME', 'GUICNT', 'GUINETTIME', 'DBP_COUNT', 'DBP_TIME', 'DSQLCNT', 'QUECNT',
                'CPICCNT', 'SLI_CNT', 'TAB1DIRCNT', 'TAB1SEQCNT', 'TAB1UPDCNT', 'TAB2DIRCNT',
                'TAB2SEQCNT', 'TAB2UPDCNT', 'TAB3DIRCNT', 'TAB3SEQCNT', 'TAB3UPDCNT', 'TAB4DIRCNT',
                'TAB4SEQCNT', 'TAB4UPDCNT', 'TAB5DIRCNT', 'TAB5SEQCNT', 'TAB5UPDCNT',
                'READDIRCNT', 'READDIRTI', 'READDIRBUF', 'READDIRREC', 'READSEQCNT', 'READSEQTI',
                'READSEQBUF', 'READSEQREC', 'PHYREADCNT', 'INSCNT', 'INSTI', 'INSREC', 'PHYINSCNT',
                'UPDCNT', 'UPDTI', 'UPDREC', 'PHYUPDCNT', 'DELCNT', 'DELTI', 'DELREC', 'PHYDELCNT',
                'DBCALLS', 'COMMITTI', 'INPUTLEN', 'OUTPUTLEN', 'MAXROLL', 'MAXPAGE',
                'ROLLINCNT', 'ROLLINTI', 'ROLLOUTCNT', 'ROLLOUTTI', 'ROLLED_OUT', 'PRIVSUM',
                'USEDBYTES', 'MAXBYTES', 'MAXBYTESDI', 'RFCRECEIVE', 'RFCSEND',
                'RFCEXETIME', 'RFCCALLTIM', 'RFCCALLS', 'VMC_CALL_COUNT', 'VMC_CPU_TIME', 'VMC_ELAP_TIME'
            ]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float)
            
            if 'ENDDATE' in df.columns and 'ENDTIME' in df.columns:
                df['ENDTIME_STR'] = df['ENDTIME'].astype(str).str.zfill(6)
                df['FULL_DATETIME'] = pd.to_datetime(df['ENDDATE'].astype(str) + df['ENDTIME_STR'], format='%Y%m%d%H%M%S', errors='coerce')
                df.drop(columns=['ENDTIME_STR'], inplace=True, errors='ignore')
            elif 'FULL_DATETIME' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['FULL_DATETIME']):
                df['FULL_DATETIME'] = pd.to_datetime(df['FULL_DATETIME'], errors='coerce')

            subset_cols_hitlist = []
            if 'RESPTI' in df.columns: subset_cols_hitlist.append('RESPTI')
            if 'PROCTI' in df.columns: subset_cols_hitlist.append('PROCTI')
            if 'CPUTI' in df.columns: subset_cols_hitlist.append('CPUTI')
            if 'DBCALLS' in df.columns: subset_cols_hitlist.append('DBCALLS')
            if subset_cols_hitlist:
                df.dropna(subset=subset_cols_hitlist, inplace=True)
            if 'FULL_DATETIME' in df.columns:
                df.dropna(subset=['FULL_DATETIME'], inplace=True)

            for col in ['WPID', 'ACCOUNT', 'REPORT', 'ROLLKEY', 'PRIVMODE', 'WPRESTART']: # Removed 'TASKTYPE'
                if col in df.columns:
                    df[col] = clean_string_column(df[col])


        elif file_key == "times":
            numeric_cols = [
                'COUNT', 'LUW_COUNT', 'RESPTI', 'PROCTI', 'CPUTI', 'QUEUETI', 'ROLLWAITTI',
                'GUITIME', 'GUICNT', 'GUINETTIME', 'DBP_COUNT', 'DBP_TIME', 'READDIRCNT',
                'READDIRTI', 'READDIRBUF', 'READDIRREC', 'READSEQCNT', 'READSEQTI',
                'READSEQBUF', 'READSEQREC', 'CHNGCNT', 'CHNGTI', 'CHNGREC', 'PHYREADCNT',
                'PHYCHNGREC', 'PHYCALLS', 'VMC_CALL_COUNT', 'VMC_CPU_TIME', 'VMC_ELAP_TIME'
            ]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float)
            
            subset_cols_times = []
            if 'RESPTI' in df.columns: subset_cols_times.append('RESPTI')
            if 'PHYCALLS' in df.columns: subset_cols_times.append('PHYCALLS')
            if 'COUNT' in df.columns: subset_cols_times.append('COUNT')
            if subset_cols_times:
                df.dropna(subset=subset_cols_times, inplace=True)
            
            if 'TIME' in df.columns:
                df['TIME'] = clean_string_column(df['TIME'])
            # TASKTYPE removal: Removed df['TASKTYPE'] = clean_string_column(df['TASKTYPE'])
            if 'ENTRY_ID' in df.columns:
                df['ENTRY_ID'] = clean_string_column(df[col])

        elif file_key == "tasktimes":
            numeric_cols = [
                'COUNT', 'RESPTI', 'PROCTI', 'CPUTI', 'QUEUETI', 'ROLLWAITTI', 'GUITIME',
                'GUICNT', 'GUINETTIME', 'DBP_COUNT', 'DBP_TIME', 'READDIRCNT', 'READDIRTI',
                'READDIRBUF', 'READDIRREC', 'READSEQCNT', 'READSEQTI',
                'READSEQBUF', 'READSEQREC', 'CHNGCNT', 'CHNGTI', 'CHNGREC', 'PHYREADCNT',
                'PHYCHNGREC', 'PHYCALLS', 'CNT001', 'CNT002', 'CNT003', 'CNT004', 'CNT005', 'CNT006', 'CNT007', 'CNT008', 'CNT009'
            ]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float)
            
            subset_cols_tasktimes = []
            if 'COUNT' in df.columns: subset_cols_tasktimes.append('COUNT')
            if 'RESPTI' in df.columns: subset_cols_tasktimes.append('RESPTI')
            if 'CPUTI' in df.columns: subset_cols_tasktimes.append('CPUTI')
            if subset_cols_tasktimes:
                df.dropna(subset=subset_cols_tasktimes, inplace=True)
            
            # TASKTYPE removal: Removed df['TASKTYPE'] = clean_string_column(df['TASKTYPE'], 'Type de t√¢che non sp√©cifi√©')
            if 'TIME' in df.columns:
                df['TIME'] = clean_string_column(df['TIME'])


        elif file_key == "usertcode":
            numeric_cols = [
                'COUNT', 'DCOUNT', 'UCOUNT', 'BCOUNT', 'ECOUNT', 'SCOUNT', 'LUW_COUNT',
                'TMBYTESIN', 'TMBYTESOUT', 'RESPTI', 'PROCTI', 'CPUTI', 'QUEUETI',
                'ROLLWAITTI', 'GUITIME', 'GUICNT', 'GUINETTIME', 'DBP_COUNT', 'DBP_TIME',
                'READDIRCNT', 'READDIRTI', 'READDIRBUF', 'READDIRREC', 'READSEQCNT',
                'READSEQTI', 'READSEQBUF', 'READSEQREC', 'CHNGCNT', 'CHNGTI', 'CHNGREC',
                'PHYREADCNT', 'PHYCHNGREC', 'PHYCALLS', 'DSQLCNT', 'QUECNT', 'CPICCNT',
                'SLI_CNT', 'VMC_CALL_COUNT', 'VMC_CPU_TIME', 'VMC_ELAP_TIME'
            ]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float)
            
            # Add FULL_DATETIME creation for usertcode
            if 'ENDDATE' in df.columns and 'ENDTIME' in df.columns:
                df['ENDTIME_STR'] = df['ENDTIME'].astype(str).str.zfill(6)
                df['FULL_DATETIME'] = pd.to_datetime(df['ENDDATE'].astype(str) + df['ENDTIME_STR'], format='%Y%m%d%H%M%S', errors='coerce')
                df.drop(columns=['ENDTIME_STR'], inplace=True, errors='ignore')
            elif 'FULL_DATETIME' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['FULL_DATETIME']):
                df['FULL_DATETIME'] = pd.to_datetime(df['FULL_DATETIME'], errors='coerce')

            critical_usertcode_cols = []
            if 'RESPTI' in df.columns: critical_usertcode_cols.append('RESPTI')
            if 'ACCOUNT' in df.columns: critical_usertcode_cols.append('ACCOUNT')
            if 'COUNT' in df.columns: critical_usertcode_cols.append('COUNT')
            
            if critical_usertcode_cols:
                df.dropna(subset=critical_usertcode_cols, inplace=True)
            
            for col in ['ENTRY_ID', 'ACCOUNT']: # Removed 'TASKTYPE'
                if col in df.columns:
                    df[col] = clean_string_column(df[col])

        elif file_key == "performance": # Nouveau bloc pour AL_GET_PERFORMANCE
            # Convertir WP_CPU de MM:SS en secondes
            if 'WP_CPU' in df.columns:
                df['WP_CPU_SECONDS'] = df['WP_CPU'].apply(convert_mm_ss_to_seconds).astype(float)
            
            # Convertir WP_IWAIT en secondes (s'il est en ms, diviser par 1000)
            if 'WP_IWAIT' in df.columns:
                df['WP_IWAIT'] = pd.to_numeric(df['WP_IWAIT'], errors='coerce').fillna(0)
                # Keep WP_IWAIT as is, we will use it for plotting.
                # df['WP_IWAIT_SECONDS'] = df['WP_IWAIT'] / 1000.0 # This conversion might not be universally needed
            else:
                df['WP_IWAIT'] = 0 # Ensure column exists even if empty

            # Nettoyage des colonnes string
            for col in ['WP_SEMSTAT', 'WP_IACTION', 'WP_ITYPE', 'WP_RESTART', 'WP_ISTATUS', 'WP_TYP', 'WP_STATUS']:
                if col in df.columns:
                    df[col] = clean_string_column(df[col])
            
            # Nettoyage des colonnes num√©riques
            numeric_cols_perf = ['WP_NO', 'WP_IRESTRT', 'WP_PID', 'WP_INDEX']
            for col in numeric_cols_perf:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(float)
            
            # Supprimer les lignes avec des valeurs critiques manquantes si n√©cessaire
            subset_cols_perf = []
            if 'WP_CPU_SECONDS' in df.columns: subset_cols_perf.append('WP_CPU_SECONDS')
            if 'WP_STATUS' in df.columns: subset_cols_perf.append('WP_STATUS')
            if subset_cols_perf:
                df.dropna(subset=subset_cols_perf, inplace=True)
        
        elif file_key == "sql_trace_summary": # Nouveau bloc pour performance_trace_summary
            # Nettoyage des colonnes num√©riques avec virgule/espace
            numeric_cols_sql = ['TOTALEXEC', 'IDENTSEL', 'EXECTIME', 'RECPROCNUM', 'TIMEPEREXE', 'RECPEREXE', 'AVGTPERREC', 'MINTPERREC']
            for col in numeric_cols_sql:
                if col in df.columns:
                    df[col] = clean_numeric_with_comma(df[col]).astype(float)
            
            # Nettoyage des colonnes string
            for col in ['SQLSTATEM', 'SERVERNAME', 'TRANS_ID']:
                if col in df.columns:
                    df[col] = clean_string_column(df[col])
            
            # Supprimer les lignes avec des valeurs critiques manquantes si n√©cessaire
            subset_cols_sql = []
            if 'EXECTIME' in df.columns: subset_cols_sql.append('EXECTIME')
            if 'TOTALEXEC' in df.columns: subset_cols_sql.append('TOTALEXEC')
            if 'SQLSTATEM' in df.columns: subset_cols_sql.append('SQLSTATEM')
            if subset_cols_sql:
                df.dropna(subset=subset_cols_sql, inplace=True)

        elif file_key == "usr02": # Nouveau bloc pour usr02_data.xlsx
            # Nettoyage des colonnes string
            for col in ['BNAME', 'USTYP']:
                if col in df.columns:
                    df[col] = clean_string_column(df[col])
            
            # Conversion de GLTGB en datetime
            if 'GLTGB' in df.columns:
                df['GLTGB'] = df['GLTGB'].astype(str).replace('00000000', np.nan)
                df['GLTGB_DATE'] = pd.to_datetime(df['GLTGB'], format='%Y%m%d', errors='coerce')
            else:
                df['GLTGB_DATE'] = pd.NaT

        return df

    except FileNotFoundError:
        st.error(f"Erreur: Le fichier '{path}' pour '{file_key}' est introuvable. Veuillez v√©rifier le chemin.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Une erreur est survenue lors du traitement du fichier '{file_key}' : {e}. D√©tails : {e}")
        return pd.DataFrame()

# --- Chargement de TOUTES les donn√©es ---
dfs = {}
for key, path in DATA_PATHS.items():
    dfs[key] = load_and_process_data(key, path)

# --- Contenu principal du Dashboard ---
st.title("üìä Tableau de Bord SAP Complet Multi-Sources")
st.markdown("Explorez les performances, l'utilisation m√©moire, les transactions utilisateurs et la sant√© du syst√®me √† travers diff√©rentes sources de donn√©es.")

# --- Affichage des KPIs ---
st.markdown("---")
kpi_cols = st.columns(5)

# KPI 1: Temps de R√©ponse Moyen Global (Hitlist DB)
avg_resp_time = 0
if not dfs['hitlist_db'].empty and 'RESPTI' in dfs['hitlist_db'].columns:
    # Ensure RESPTI is numeric before mean calculation
    if pd.api.types.is_numeric_dtype(dfs['hitlist_db']['RESPTI']):
        avg_resp_time = dfs['hitlist_db']['RESPTI'].mean() / 1000
kpi_cols[0].metric("Temps de R√©ponse Moyen (s)", f"{avg_resp_time:.2f}")

# KPI 2: Utilisation M√©moire Moyenne (USEDBYTES)
avg_memory_usage = 0
if not dfs['memory'].empty and 'USEDBYTES' in dfs['memory'].columns:
    # Ensure USEDBYTES is numeric before mean calculation
    if pd.api.types.is_numeric_dtype(dfs['memory']['USEDBYTES']):
        avg_memory_usage = dfs['memory']['USEDBYTES'].mean() / (1024 * 1024)
kpi_cols[1].metric("M√©moire Moyenne (Mo)", f"{avg_memory_usage:.2f}")

# KPI 3: Total des Appels Base de Donn√©es (Hitlist DB)
total_db_calls = 0
if not dfs['hitlist_db'].empty and 'DBCALLS' in dfs['hitlist_db'].columns:
    # Ensure DBCALLS is numeric before sum calculation
    if pd.api.types.is_numeric_dtype(dfs['hitlist_db']['DBCALLS']):
        total_db_calls = dfs['hitlist_db']['DBCALLS'].sum()
kpi_cols[2].metric("Total Appels DB", f"{int(total_db_calls):,}".replace(",", " "))

# KPI 4: Total des Ex√©cutions SQL (performance_trace_summary) - NOUVEAU KPI
total_sql_executions = 0
if not dfs['sql_trace_summary'].empty and 'TOTALEXEC' in dfs['sql_trace_summary'].columns:
    # Ensure TOTALEXEC is numeric before sum calculation
    if pd.api.types.is_numeric_dtype(dfs['sql_trace_summary']['TOTALEXEC']):
        total_sql_executions = dfs['sql_trace_summary']['TOTALEXEC'].sum()
kpi_cols[3].metric("Total Ex√©cutions SQL", f"{int(total_sql_executions):,}".replace(",", " "))

# KPI 5: Temps CPU Moyen Global (Hitlist DB)
avg_cpu_time = 0
if not dfs['hitlist_db'].empty and 'CPUTI' in dfs['hitlist_db'].columns:
    # Ensure CPUTI is numeric before mean calculation
    if pd.api.types.is_numeric_dtype(dfs['hitlist_db']['CPUTI']):
        avg_cpu_time = dfs['hitlist_db']['CPUTI'].mean() / 1000
kpi_cols[4].metric("Temps CPU Moyen (s)", f"{avg_cpu_time:.2f}")

st.markdown("---")

# --- Barre de navigation flexible ---
tab_titles = [
    "Analyse M√©moire",
    "Transactions Utilisateurs",
    "Statistiques Horaires",
    "Insights Hitlist DB",
    "Performance des Processus de Travail",
    "R√©sum√© des Traces de Performance SQL",
    "Analyse des Utilisateurs",
    "D√©tection d'Anomalies",
    "Pr√©diction de Performance (ML)"
]

if 'current_section' not in st.session_state:
    st.session_state.current_section = tab_titles[0]

st.sidebar.header("Navigation Rapide")
selected_section = st.sidebar.radio(
    "Acc√©der √† la section :",
    tab_titles,
    index=tab_titles.index(st.session_state.current_section)
)

st.session_state.current_section = selected_section

if all(df.empty for df in dfs.values()):
    st.error("Aucune source de donn√©es n'a pu √™tre charg√©e. Le dashboard ne peut pas s'afficher. Veuillez v√©rifier les chemins et les fichiers.")
else:
    # --- Sidebar pour les filtres globaux ---
    st.sidebar.header("Filtres")

    all_accounts = pd.Index([])
    if not dfs['memory'].empty and 'ACCOUNT' in dfs['memory'].columns:
        all_accounts = all_accounts.union(dfs['memory']['ACCOUNT'].dropna().unique())
    if not dfs['usertcode'].empty and 'ACCOUNT' in dfs['usertcode'].columns:
        all_accounts = all_accounts.union(dfs['usertcode']['ACCOUNT'].dropna().unique())
    if not dfs['hitlist_db'].empty and 'ACCOUNT' in dfs['hitlist_db'].columns:
        all_accounts = all_accounts.union(dfs['hitlist_db']['ACCOUNT'].dropna().unique())
    
    selected_accounts = []
    if not all_accounts.empty:
        selected_accounts = st.sidebar.multiselect(
            "S√©lectionner des Comptes",
            options=sorted(all_accounts.tolist()),
            default=[]
        )
        if selected_accounts:
            for key in ['memory', 'usertcode', 'hitlist_db']:
                if not dfs[key].empty and 'ACCOUNT' in dfs[key].columns:
                    dfs[key] = dfs[key][dfs[key]['ACCOUNT'].isin(selected_accounts)]

    selected_reports = []
    if not dfs['hitlist_db'].empty and 'REPORT' in dfs['hitlist_db'].columns:
        all_reports = dfs['hitlist_db']['REPORT'].dropna().unique().tolist()
        selected_reports = st.sidebar.multiselect(
            "S√©lectionner des Rapports (Hitlist DB)",
            options=sorted(all_reports),
            default=[]
        )
        if selected_reports:
            dfs['hitlist_db'] = dfs['hitlist_db'][dfs['hitlist_db']['REPORT'].isin(selected_reports)]
    
    # TASKTYPE removal: Removed global tasktype filter from sidebar
    # all_tasktypes = pd.Index([])
    # if not dfs['usertcode'].empty and 'TASKTYPE' in dfs['usertcode'].columns:
    #     all_tasktypes = all_tasktypes.union(dfs['usertcode']['TASKTYPE'].dropna().unique())
    # if not dfs['times'].empty and 'TASKTYPE' in dfs['times'].columns:
    #     all_tasktypes = all_tasktypes.union(dfs['times']['TASKTYPE'].dropna().unique())
    # if not dfs['tasktimes'].empty and 'TASKTYPE' in dfs['tasktimes'].columns:
    #     all_tasktypes = all_tasktypes.union(dfs['tasktimes']['TASKTYPE'].dropna().unique())
    # if not dfs['hitlist_db'].empty and 'TASKTYPE' in dfs['hitlist_db'].columns:
    #     all_tasktypes = all_tasktypes.union(dfs['hitlist_db']['TASKTYPE'].dropna().unique())
    # if not dfs['memory'].empty and 'TASKTYPE' in dfs['memory'].columns:
    #     all_tasktypes = all_tasktypes.union(dfs['memory']['TASKTYPE'].dropna().unique())

    # selected_tasktypes = []
    # if not all_tasktypes.empty:
    #     selected_tasktypes = st.sidebar.multiselect(
    #         "S√©lectionner des Types de T√¢ches",
    #         options=sorted(all_tasktypes.tolist()),
    #         default=[]
    #     )
    #     if selected_tasktypes:
    #         for key in ['usertcode', 'times', 'tasktimes', 'hitlist_db', 'memory']:
    #             if not dfs[key].empty and 'TASKTYPE' in dfs[key].columns:
    #                 dfs[key] = dfs[key][dfs[key]['TASKTYPE'].isin(selected_tasktypes)]
    
    selected_wp_types = []
    if not dfs['performance'].empty and 'WP_TYP' in dfs['performance'].columns:
        all_wp_types = dfs['performance']['WP_TYP'].dropna().unique().tolist()
        selected_wp_types = st.sidebar.multiselect(
            "S√©lectionner des Types de Work Process (Performance)",
            options=sorted(all_wp_types),
            default=[]
        )
        if selected_wp_types:
            dfs['performance'] = dfs['performance'][dfs['performance']['WP_TYP'].isin(selected_wp_types)]

    df_hitlist_filtered = dfs['hitlist_db'].copy()


    # --- Contenu des sections bas√© sur la s√©lection de la barre lat√©rale ---
    if st.session_state.current_section == "Analyse M√©moire":
        # --- Onglet 1: Analyse M√©moire (memory_final_cleaned_clean.xlsx) ---
        st.header("üß† Analyse de l'Utilisation M√©moire")
        df_mem = dfs['memory'].copy()
        if selected_accounts:
            df_mem = df_mem[df_mem['ACCOUNT'].isin(selected_accounts)]
        # TASKTYPE removal: Removed if selected_tasktypes filter for df_mem
        # if selected_tasktypes:
        #     if 'TASKTYPE' in df_mem.columns:
        #         df_mem = df_mem[df_mem['TASKTYPE'].isin(selected_tasktypes)]
        #     else:
        #         st.warning("La colonne 'TASKTYPE' est manquante dans les donn√©es m√©moire pour le filtrage.")

        if not df_mem.empty:
            st.subheader("Top 10 Utilisateurs par Utilisation M√©moire (USEDBYTES)")
            st.markdown("""
                Ce graphique identifie les 10 principaux utilisateurs ou comptes consommant le plus de m√©moire (USEDBYTES). Il est essentiel pour d√©tecter les "gros consommateurs" de ressources, comme JBELIM qui domine l'utilisation et ainsi cibler les optimisations de performance syst√®me. 
                Il aide √† comprendre qui ou quel processus ABAP (comme WF-BATCH) impacte le plus les ressources m√©moire.


                """)
            if all(col in df_mem.columns for col in ['ACCOUNT', 'USEDBYTES', 'MAXBYTES', 'PRIVSUM']) and df_mem['USEDBYTES'].sum() > 0:
                # Ensure numeric types before aggregation
                df_mem['USEDBYTES'] = pd.to_numeric(df_mem['USEDBYTES'], errors='coerce').fillna(0).astype(float)
                df_mem['MAXBYTES'] = pd.to_numeric(df_mem['MAXBYTES'], errors='coerce').fillna(0).astype(float)
                df_mem['PRIVSUM'] = pd.to_numeric(df_mem['PRIVSUM'], errors='coerce').fillna(0).astype(float)

                top_users_mem = df_mem.groupby('ACCOUNT', as_index=False)[['USEDBYTES', 'MAXBYTES', 'PRIVSUM']].sum().nlargest(10, 'USEDBYTES')
                if not top_users_mem.empty and top_users_mem['USEDBYTES'].sum() > 0:
                    fig_top_users_mem = px.bar(top_users_mem,
                                                x='ACCOUNT', y='USEDBYTES',
                                                title="Top 10 Comptes par USEDBYTES Total",
                                                labels={'USEDBYTES': 'Utilisation M√©moire (Octets)', 'ACCOUNT': 'Compte Utilisateur'},
                                                hover_data=['MAXBYTES', 'PRIVSUM'],
                                                color='USEDBYTES', color_continuous_scale=px.colors.sequential.Plasma)
                    st.plotly_chart(fig_top_users_mem, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Top 10 Utilisateurs par Utilisation M√©moire apr√®s filtrage.")
            else:
                st.info("Colonnes n√©cessaires (ACCOUNT, USEDBYTES, MAXBYTES, PRIVSUM) manquantes ou USEDBYTES total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Moyenne de USEDBYTES par Client (ACCOUNT)")
            st.markdown("""
                Cette visualisation pr√©sente la consommation moyenne de m√©moire (USEDBYTES) par client ou compte SAP. 
                Elle offre une perspective agr√©g√©e, utile pour la planification des capacit√©s et la compr√©hension des tendances d'utilisation par groupe fonctionnel ou type d'activit√©. 
                Cela permet d'allouer les ressources m√©moire plus efficacement en fonction des besoins moyens des diff√©rents clients.
                """)
            if 'ACCOUNT' in df_mem.columns and 'USEDBYTES' in df_mem.columns and df_mem['USEDBYTES'].sum() > 0:
                df_mem_account_clean = df_mem[df_mem['ACCOUNT'] != 'Compte Inconnu'].copy()
                
                if not df_mem_account_clean.empty:
                    # Ensure USEDBYTES is numeric here
                    df_mem_account_clean['USEDBYTES'] = pd.to_numeric(df_mem_account_clean['USEDBYTES'], errors='coerce').fillna(0).astype(float)
                    df_mem_account_clean['ACCOUNT_DISPLAY'] = df_mem_account_clean['ACCOUNT'].astype(str)

                    account_counts = df_mem_account_clean['ACCOUNT_DISPLAY'].nunique()
                    if account_counts > 6:
                        top_accounts = df_mem_account_clean['ACCOUNT_DISPLAY'].value_counts().nlargest(6).index
                        df_mem_account_filtered_for_plot = df_mem_account_clean.loc[df_mem_account_clean['ACCOUNT_DISPLAY'].isin(top_accounts)].copy()
                    else:
                        df_mem_account_filtered_for_plot = df_mem_account_clean.copy()

                    avg_mem_account = df_mem_account_filtered_for_plot.groupby('ACCOUNT_DISPLAY', as_index=False)['USEDBYTES'].mean().sort_values(by='USEDBYTES', ascending=False)
                    if not avg_mem_account.empty and not avg_mem_account['USEDBYTES'].sum() == 0:
                        fig_avg_mem_account = px.bar(avg_mem_account,
                                                     x='ACCOUNT_DISPLAY', y='USEDBYTES',
                                                     title="Moyenne de USEDBYTES par Client SAP (Top 6 ou tous)",
                                                     labels={'USEDBYTES': 'Moyenne USEDBYTES (Octets)', 'ACCOUNT_DISPLAY': 'Client SAP'},
                                                     color='USEDBYTES', color_continuous_scale=px.colors.sequential.Viridis)
                        fig_avg_mem_account.update_xaxes(type='category')
                        st.plotly_chart(fig_avg_mem_account, use_container_width=True)
                    else:
                        st.info("Pas de donn√©es valides pour la moyenne de USEDBYTES par Client SAP apr√®s filtrage (peut-√™tre tous 'Compte Inconnu' ou USEDBYTES est z√©ro).")
                else:
                    st.info("Aucune donn√©e valide pour les clients (ACCOUNT) apr√®s filtrage.")
            else:
                st.info("Colonnes 'ACCOUNT' ou 'USEDBYTES' manquantes ou USEDBYTES total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Distribution de l'Utilisation M√©moire (USEDBYTES) - Courbe de Densit√©")
            st.markdown("""
                 "Densit√©" indique la fr√©quence relative √† laquelle une valeur d'utilisation m√©moire appara√Æt. 
                 Un pic √©lev√© sur la courbe signifie que les valeurs de USEDBYTES autour de ce point sont tr√®s fr√©quentes. 
                 √Ä l'inverse, une faible densit√© (la courbe se rapprochant de z√©ro) indique que ces niveaux de consommation m√©moire sont rares.
                """)
            if 'USEDBYTES' in df_mem.columns and df_mem['USEDBYTES'].sum() > 0:
                # Ensure USEDBYTES is numeric here
                df_mem['USEDBYTES'] = pd.to_numeric(df_mem['USEDBYTES'], errors='coerce').fillna(0).astype(float)
                if df_mem['USEDBYTES'].nunique() > 1:
                    fig_dist_mem = ff.create_distplot([df_mem['USEDBYTES'].dropna()], ['USEDBYTES'], bin_size=df_mem['USEDBYTES'].std()/5 if df_mem['USEDBYTES'].std() > 0 else 1, show_rug=False, show_hist=False)
                    fig_dist_mem.update_layout(title_text="Distribution de l'Utilisation M√©moire (USEDBYTES) - Courbe de Densit√©", xaxis_title='Utilisation M√©moire (Octets)', yaxis_title='Densit√©')
                    fig_dist_mem.data[0].line.color = 'lightcoral'
                    st.plotly_chart(fig_dist_mem, use_container_width=True)
                else:
                    st.info("La colonne 'USEDBYTES' contient des valeurs uniques ou est vide apr√®s filtrage, impossible de cr√©er une courbe de densit√©.")
            else:
                st.info("Colonne 'USEDBYTES' manquante ou total est z√©ro/vide apr√®s filtrage.")

            if 'FULL_DATETIME' in df_mem.columns and pd.api.types.is_datetime64_any_dtype(df_mem['FULL_DATETIME']) and not df_mem['FULL_DATETIME'].isnull().all() and 'USEDBYTES' in df_mem.columns and df_mem['USEDBYTES'].sum() > 0:
                # Ensure USEDBYTES is numeric here
                df_mem['USEDBYTES'] = pd.to_numeric(df_mem['USEDBYTES'], errors='coerce').fillna(0).astype(float)
                hourly_mem_usage = df_mem.set_index('FULL_DATETIME')['USEDBYTES'].resample('H').mean().dropna()
                if not hourly_mem_usage.empty:
                    fig_hourly_mem = px.line(hourly_mem_usage.reset_index(), x='FULL_DATETIME', y='USEDBYTES', title="Tendance Moyenne USEDBYTES par Heure", labels={'FULL_DATETIME': 'Heure', 'USEDBYTES': 'Moyenne USEDBYTES'}, color_discrete_sequence=['purple'])
                    fig_hourly_mem.update_xaxes(dtick="H1", tickformat="%H:%M")
                    st.plotly_chart(fig_hourly_mem, use_container_width=True)
                else:
                    pass # Original code had pass here, maintaining
            else:
                pass # Original code had pass here, maintaining

            st.markdown("""
                Cette courbe de densit√© illustre la distribution de l'utilisation m√©moire (USEDBYTES). Le pic prononc√© pr√®s de z√©ro indique que la majorit√© des op√©rations consomment tr√®s peu de m√©moire. La "longue queue" vers la droite r√©v√®le la pr√©sence, bien que rare, de processus gourmands en m√©moire. Il pourrait s'agir de requ√™tes complexes, de traitements de lot volumineux (comme WF-BATCH qui appara√Æt dans les autres graphiques), ou d'√©ventuels probl√®mes n√©cessitant une optimisation.
                """)
            st.subheader("Comparaison des M√©triques M√©moire (USEDBYTES, MAXBYTES, PRIVSUM) par Compte Utilisateur")
            st.markdown("""
                *USEDBYTES: M√©moire actuellement utilis√©e par un processus ou une session. *MAXBYTES: Quantit√© maximale de m√©moire atteinte par un processus pendant son ex√©cution. *PRIVSUM: Quantit√© de m√©moire priv√©e, non partag√©e, consomm√©e par un processus.
                """)
            mem_metrics_cols = ['USEDBYTES', 'MAXBYTES', 'PRIVSUM']
            if all(col in df_mem.columns for col in mem_metrics_cols) and 'ACCOUNT' in df_mem.columns and df_mem[mem_metrics_cols].sum().sum() > 0:
                # Ensure numeric types before aggregation
                for col in mem_metrics_cols:
                    df_mem[col] = pd.to_numeric(df_mem[col], errors='coerce').fillna(0).astype(float)
                account_mem_summary = df_mem.groupby('ACCOUNT', as_index=False)[mem_metrics_cols].sum().nlargest(10, 'USEDBYTES')
                if not account_mem_summary.empty and account_mem_summary[mem_metrics_cols].sum().sum() > 0:
                    fig_mem_comparison = px.bar(account_mem_summary, x='ACCOUNT', y=mem_metrics_cols, title="Comparaison des M√©triques M√©moire par Compte Utilisateur (Top 10 USEDBYTES)", labels={'value': 'Quantit√© (Octets)', 'variable': 'M√©trique M√©moire', 'ACCOUNT': 'Compte Utilisateur'}, barmode='group', color_discrete_sequence=px.colors.qualitative.Pastel)
                    st.plotly_chart(fig_mem_comparison, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour la comparaison des m√©triques m√©moire par compte utilisateur apr√®s filtrage.")
            else:
                st.info("Colonnes n√©cessaires (ACCOUNT, USEDBYTES, MAXBYTES, PRIVSUM) manquantes ou leurs totaux sont z√©ro/vides apr√®s filtrage pour la comparaison des m√©triques m√©moire.")
            # TASKTYPE removal: Removed section "Top Types de T√¢ches par Utilisation M√©moire"
            # st.subheader("Top Types de T√¢ches (TASKTYPE) par Utilisation M√©moire (USEDBYTES)")
            # if 'TASKTYPE' in df_mem.columns and 'USEDBYTES' in df_mem.columns and df_mem['USEDBYTES'].sum() > 0:
            # df_mem['USEDBYTES'] = pd.to_numeric(df_mem['USEDBYTES'], errors='coerce').fillna(0).astype(float)
            # top_tasktype_mem = df_mem.groupby('TASKTYPE', as_index=False)['USEDBYTES'].sum().nlargest(3, 'USEDBYTES')
            # if not top_tasktype_mem.empty and top_tasktype_mem['USEDBYTES'].sum() > 0:
            # fig_top_tasktype_mem = px.bar(top_tasktype_mem, x='TASKTYPE', y='USEDBYTES', title="Top 3 Types de T√¢ches par Utilisation M√©moire (USEDBYTES)", labels={'USEDBYTES': 'Utilisation M√©moire Totale (Octets)', 'TASKTYPE': 'Type de T√¢che'}, color='USEDBYTES', color_continuous_scale=px.colors.sequential.Greys)
            # st.plotly_chart(fig_top_tasktype_mem, use_container_width=True)
            # else:
            # st.info("Pas de donn√©es valides pour les Top Types de T√¢ches par Utilisation M√©moire apr√®s filtrage.")
            # else:
            # st.info("Colonnes 'TASKTYPE' ou 'USEDBYTES' manquantes ou USEDBYTES total est z√©ro/vide apr√®s filtrage pour les types de t√¢ches m√©moire.")
            st.subheader("Aper√ßu des Donn√©es M√©moire Filtr√©es")
            # Displaying only relevant columns for an overview, excluding TASKTYPE
            # TASKTYPE removal: Ensure TASKTYPE is not in this list
            columns_to_display = [col for col in df_mem.columns if col not in ['TASKTYPE', 'FULL_DATETIME']]
            st.dataframe(df_mem[columns_to_display].head())
        # FIX START: Replaced the problematic 'else' block with a new 'if' for clarity
        if df_mem.empty:
            st.warning("Donn√©es m√©moire non disponibles ou filtr√©es √† vide.")
        # FIX END
    elif st.session_state.current_section == "Transactions Utilisateurs":
        # --- Onglet 2: Transactions Utilisateurs (USERTCODE_cleaned.xlsx) ---
        st.header("üë§ Analyse des Transactions Utilisateurs")
        df_user = dfs['usertcode'].copy()
        if selected_accounts:
            if 'ACCOUNT' in df_user.columns:
                df_user = df_user[df_user['ACCOUNT'].isin(selected_accounts)]
            else:
                st.warning("La colonne 'ACCOUNT' est manquante dans les donn√©es utilisateurs pour le filtrage.")
        # TASKTYPE removal: Removed if selected_tasktypes filter for df_user
        # if selected_tasktypes:
        #     if 'TASKTYPE' in df_user.columns:
        #         df_user = df_user[df_user['TASKTYPE'].isin(selected_tasktypes)]
        #     else:
        #         st.warning("La colonne 'TASKTYPE' est manquante dans les donn√©es utilisateurs pour le filtrage.")
        if not df_user.empty:
            # --- Section modifi√©e: Top 10 des Comptes (ACCOUNT) par Temps de R√©ponse Moyen (en cercle) ---
            st.subheader("Top 10 des Comptes (ACCOUNT) par Temps de R√©ponse Moyen")
            st.markdown("""
                Ce graphique montre la distribution des appels de base de donn√©es par serveur, ce qui est crucial pour identifier 
                les serveurs surcharg√©s ou sous-utilis√©s et optimiser la r√©partition de la charge.
                """)
            
            if all(col in df_user.columns for col in ['ACCOUNT', 'RESPTI']) and df_user['RESPTI'].sum() > 0:
                df_user['RESPTI'] = pd.to_numeric(df_user['RESPTI'], errors='coerce').fillna(0).astype(float)
                top_accounts_resp = df_user.groupby('ACCOUNT', as_index=False)['RESPTI'].mean().nlargest(10, 'RESPTI')
                
                if not top_accounts_resp.empty and top_accounts_resp['RESPTI'].sum() > 0:
                    fig_top_accounts_resp = px.pie(top_accounts_resp, values='RESPTI', names='ACCOUNT',
                                                 title="Top 10 Comptes par Temps de R√©ponse Moyen (ms)",
                                                 hole=0.3)
                    fig_top_accounts_resp.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig_top_accounts_resp, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Top 10 Comptes par Temps de R√©ponse Moyen apr√®s filtrage.")
            else:
                st.info("Colonnes 'ACCOUNT' ou 'RESPTI' manquantes ou RESPTI total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Nombre de Transactions par TCode (Top 10)")
            st.markdown("""
                Ce graphique en barres pr√©sente les 10 codes de transaction (TCode) les plus fr√©quemment utilis√©s. Il permet d'identifier 
                les fonctionnalit√©s les plus sollicit√©es dans SAP, ce qui est utile pour la planification des ressources et l'identification des processus m√©tier cl√©s.
                """)
            if 'ENTRY_ID' in df_user.columns and 'COUNT' in df_user.columns and df_user['COUNT'].sum() > 0:
                df_user['COUNT'] = pd.to_numeric(df_user['COUNT'], errors='coerce').fillna(0).astype(float)
                top_tcodes = df_user.groupby('ENTRY_ID', as_index=False)['COUNT'].sum().nlargest(10, 'COUNT')
                if not top_tcodes.empty and top_tcodes['COUNT'].sum() > 0:
                    fig_top_tcodes = px.bar(top_tcodes, x='ENTRY_ID', y='COUNT',
                                            title="Top 10 TCodes par Nombre de Transactions",
                                            labels={'ENTRY_ID': 'Code de Transaction (TCode)', 'COUNT': 'Nombre de Transactions'},
                                            color='COUNT', color_continuous_scale=px.colors.sequential.Sunset)
                    st.plotly_chart(fig_top_tcodes, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Top 10 TCodes apr√®s filtrage.")
            else:
                st.info("Colonnes 'ENTRY_ID' ou 'COUNT' manquantes ou COUNT total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Distribution du Temps de R√©ponse (RESPTI) par Type d'Utilisateur (USTYP) - USR02")
            st.markdown("""
                Cette analyse explore comment le temps de r√©ponse des transactions varie en fonction des types d'utilisateurs (par exemple, dialogue, batch). 
                Elle aide √† comprendre les impacts des diff√©rents profils d'utilisation sur la performance globale du syst√®me SAP et √† identifier les goulots d'√©tranglement 
                sp√©cifiques √† certains types d'activit√©s.
                """)
            # Merge with usr02 to get USTYP
            if not dfs['usr02'].empty and not df_user.empty and 'ACCOUNT' in df_user.columns and 'BNAME' in dfs['usr02'].columns and 'RESPTI' in df_user.columns:
                df_merged_user_type = pd.merge(df_user, dfs['usr02'][['BNAME', 'USTYP']], left_on='ACCOUNT', right_on='BNAME', how='left')
                if 'USTYP' in df_merged_user_type.columns and not df_merged_user_type['USTYP'].isnull().all() and df_merged_user_type['RESPTI'].sum() > 0:
                    df_merged_user_type['RESPTI'] = pd.to_numeric(df_merged_user_type['RESPTI'], errors='coerce').fillna(0).astype(float)
                    
                    # Filter out NaN/None USTYP
                    df_merged_user_type_clean = df_merged_user_type.dropna(subset=['USTYP']).copy()
                    
                    if not df_merged_user_type_clean.empty and df_merged_user_type_clean['USTYP'].nunique() > 1:
                        # Ensure 'RESPTI' column has variation for meaningful box plot
                        if df_merged_user_type_clean.groupby('USTYP')['RESPTI'].nunique().min() > 1:
                            fig_resp_by_user_type = px.box(df_merged_user_type_clean, x='USTYP', y='RESPTI',
                                                        title="Distribution du Temps de R√©ponse (RESPTI) par Type d'Utilisateur",
                                                        labels={'USTYP': "Type d'Utilisateur", 'RESPTI': 'Temps de R√©ponse (ms)'},
                                                        color='USTYP')
                            st.plotly_chart(fig_resp_by_user_type, use_container_width=True)
                        else:
                            st.info("La colonne 'RESPTI' ne contient pas suffisamment de variation pour cr√©er un Box Plot significatif pour chaque type d'utilisateur.")
                    else:
                        st.info("Pas de donn√©es valides pour la distribution du Temps de R√©ponse par Type d'Utilisateur apr√®s filtrage.")
                else:
                    st.info("Colonnes 'USTYP' ou 'RESPTI' manquantes/vides apr√®s fusion, ou RESPTI total est z√©ro/vide.")
            else:
                st.info("Donn√©es 'usr02' ou 'usertcode' non disponibles ou colonnes requises manquantes pour l'analyse par type d'utilisateur.")

            st.subheader("Aper√ßu des Donn√©es Utilisateurs Filtr√©es")
            # TASKTYPE removal: Ensure TASKTYPE is not in this list
            columns_to_display_user = [col for col in df_user.columns if col not in ['TASKTYPE', 'FULL_DATETIME']]
            st.dataframe(df_user[columns_to_display_user].head())
        else:
            st.warning("Donn√©es utilisateurs non disponibles ou filtr√©es √† vide.")

    elif st.session_state.current_section == "Statistiques Horaires":
        # --- Onglet 3: Statistiques Horaires (Times_final_cleaned_clean.xlsx & TASKTIMES_final_cleaned_clean.xlsx) ---
        st.header("‚è∞ Statistiques Horaires et Types de T√¢ches")

        st.subheader("Temps de R√©ponse Moyen (RESPTI) par Heure (Times)")
        st.markdown("""
            Ce graphique en aires repr√©sente l'√©volution du temps de r√©ponse moyen par heure. 
            Il aide √† identifier les p√©riodes de pointe o√π le syst√®me est le plus sollicit√©, 
            ce qui est crucial pour la planification de la capacit√© et l'optimisation des performances en fonction des cycles d'activit√©.
            """)
        df_times = dfs['times'].copy()
        # TASKTYPE removal: Removed if selected_tasktypes filter for df_times
        # if selected_tasktypes:
        #     if 'TASKTYPE' in df_times.columns:
        #         df_times = df_times[df_times['TASKTYPE'].isin(selected_tasktypes)]
        #     else:
        #         st.warning("La colonne 'TASKTYPE' est manquante dans les donn√©es 'times' pour le filtrage.")

        if not df_times.empty and 'TIME' in df_times.columns and 'RESPTI' in df_times.columns and df_times['RESPTI'].sum() > 0:
            df_times['RESPTI'] = pd.to_numeric(df_times['RESPTI'], errors='coerce').fillna(0).astype(float)
            
            # Convert TIME column to proper time format for sorting
            df_times['TIME_HOUR_MIN'] = pd.to_datetime(df_times['TIME'], format='%H:%M:%S', errors='coerce').dt.time
            df_times_clean = df_times.dropna(subset=['TIME_HOUR_MIN']).copy()

            if not df_times_clean.empty:
                hourly_resp_time = df_times_clean.groupby('TIME_HOUR_MIN')['RESPTI'].mean().reset_index()
                hourly_resp_time['TIME_STR'] = hourly_resp_time['TIME_HOUR_MIN'].astype(str) # For display
                hourly_resp_time = hourly_resp_time.sort_values(by='TIME_HOUR_MIN')

                if not hourly_resp_time.empty and hourly_resp_time['RESPTI'].sum() > 0:
                    fig_hourly_resp = px.area(hourly_resp_time, x='TIME_STR', y='RESPTI',
                                            title="Temps de R√©ponse Moyen (RESPTI) par Heure (Times)",
                                            labels={'TIME_STR': 'Heure de la Journ√©e', 'RESPTI': 'Temps de R√©ponse Moyen (ms)'},
                                            color_discrete_sequence=['deepskyblue'])
                    fig_hourly_resp.update_xaxes(type='category', categoryorder='array', categoryarray=hourly_resp_time['TIME_STR'].tolist())
                    st.plotly_chart(fig_hourly_resp, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour le Temps de R√©ponse Moyen par Heure apr√®s filtrage.")
            else:
                st.info("La colonne 'TIME' est vide ou contient des formats non valides apr√®s filtrage.")
        else:
            st.info("Colonnes 'TIME' ou 'RESPTI' manquantes dans 'Times' ou RESPTI total est z√©ro/vide.")

        st.subheader("Temps CPU Moyen par Heure (Tasktimes)")
        st.markdown("""
            Ce graphique illustre la consommation moyenne de temps CPU par heure, offrant une vue d√©taill√©e des p√©riodes o√π les ressources de traitement 
            sont le plus sollicit√©es. Cette information est essentielle pour le r√©glage fin des performances du syst√®me et la r√©partition des charges de travail.
            """)
        df_tasktimes = dfs['tasktimes'].copy()
        # TASKTYPE removal: Removed if selected_tasktypes filter for df_tasktimes
        # if selected_tasktypes:
        #     if 'TASKTYPE' in df_tasktimes.columns:
        #         df_tasktimes = df_tasktimes[df_tasktimes['TASKTYPE'].isin(selected_tasktypes)]
        #     else:
        #         st.warning("La colonne 'TASKTYPE' est manquante dans les donn√©es 'tasktimes' pour le filtrage.")

        if not df_tasktimes.empty and 'TIME' in df_tasktimes.columns and 'CPUTI' in df_tasktimes.columns and df_tasktimes['CPUTI'].sum() > 0:
            df_tasktimes['CPUTI'] = pd.to_numeric(df_tasktimes['CPUTI'], errors='coerce').fillna(0).astype(float)
            
            # Convert TIME column to proper time format for sorting
            df_tasktimes['TIME_HOUR_MIN'] = pd.to_datetime(df_tasktimes['TIME'], format='%H:%M:%S', errors='coerce').dt.time
            df_tasktimes_clean = df_tasktimes.dropna(subset=['TIME_HOUR_MIN']).copy()

            if not df_tasktimes_clean.empty:
                hourly_cpu_time = df_tasktimes_clean.groupby('TIME_HOUR_MIN')['CPUTI'].mean().reset_index()
                hourly_cpu_time['TIME_STR'] = hourly_cpu_time['TIME_HOUR_MIN'].astype(str) # For display
                hourly_cpu_time = hourly_cpu_time.sort_values(by='TIME_HOUR_MIN')
                
                if not hourly_cpu_time.empty and hourly_cpu_time['CPUTI'].sum() > 0:
                    fig_hourly_cpu = px.line(hourly_cpu_time, x='TIME_STR', y='CPUTI',
                                            title="Temps CPU Moyen (CPUTI) par Heure (Tasktimes)",
                                            labels={'TIME_STR': 'Heure de la Journ√©e', 'CPUTI': 'Temps CPU Moyen (ms)'},
                                            color_discrete_sequence=['orange'])
                    fig_hourly_cpu.update_xaxes(type='category', categoryorder='array', categoryarray=hourly_cpu_time['TIME_STR'].tolist())
                    st.plotly_chart(fig_hourly_cpu, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour le Temps CPU Moyen par Heure apr√®s filtrage.")
            else:
                st.info("La colonne 'TIME' est vide ou contient des formats non valides apr√®s filtrage.")
        else:
            st.info("Colonnes 'TIME' ou 'CPUTI' manquantes dans 'Tasktimes' ou CPUTI total est z√©ro/vide.")

        st.subheader("Nombre de Traitements par T√¢che (COUNT) (Tasktimes)")
        st.markdown("""
            Ce graphique met en √©vidence les types de t√¢ches les plus fr√©quemment ex√©cut√©es dans le syst√®me. Il offre un aper√ßu de la charge de travail 
            et des patterns d'utilisation, aidant √† identifier les t√¢ches dominantes qui pourraient n√©cessiter une attention particuli√®re pour l'optimisation.
            """)
        if not df_tasktimes.empty and 'COUNT' in df_tasktimes.columns and df_tasktimes['COUNT'].sum() > 0:
            df_tasktimes['COUNT'] = pd.to_numeric(df_tasktimes['COUNT'], errors='coerce').fillna(0).astype(float)
            
            # Assuming 'ENTRY_ID' or similar column for task type, if not, use a generic count
            # Based on file_key "tasktimes", the data might not have a direct 'TASKTYPE' column.
            # If there's another column that represents task type, use it. Otherwise, count generally.
            # For this example, let's just show total count or a distribution if a suitable column exists.
            
            # If there's a column like 'ENTRY_ID' or 'TASKTYPE' to group by
            # For tasktimes, if a column like 'ENTRY_ID' or 'TASKTYPE' is present, use it.
            # If not, a simple sum of COUNT might be more appropriate.
            # Given the previous TASKTYPE removal, we'll just sum counts.
            total_task_count = df_tasktimes['COUNT'].sum()
            st.metric("Total des Traitements (Tasktimes)", f"{int(total_task_count):,}".replace(",", " "))
        else:
            st.info("Colonne 'COUNT' manquante dans 'Tasktimes' ou total est z√©ro/vide.")
        
        st.subheader("Aper√ßu des Donn√©es Statistiques Horaires Filtr√©es (Times)")
        columns_to_display_times = [col for col in df_times.columns if col not in ['TASKTYPE', 'TIME_HOUR_MIN']]
        st.dataframe(df_times[columns_to_display_times].head())

        st.subheader("Aper√ßu des Donn√©es Statistiques Horaires Filtr√©es (Tasktimes)")
        columns_to_display_tasktimes = [col for col in df_tasktimes.columns if col not in ['TASKTYPE', 'TIME_HOUR_MIN']]
        st.dataframe(df_tasktimes[columns_to_display_tasktimes].head())
        
        if df_times.empty and df_tasktimes.empty:
            st.warning("Donn√©es horaires non disponibles ou filtr√©es √† vide.")

    elif st.session_state.current_section == "Insights Hitlist DB":
        # --- Onglet 4: Insights Hitlist DB (HITLIST_DATABASE_final_cleaned_clean.xlsx) ---
        st.header("üîç Insights sur la Base de Donn√©es (Hitlist DB)")
        df_hitlist = df_hitlist_filtered.copy() # Use the already filtered df

        if not df_hitlist.empty:
            st.subheader("Distribution du Temps de R√©ponse (RESPTI) par Rapport (REPORT) - Top 10")
            st.markdown("""
                Ce graphique en barres pr√©sente les temps de r√©ponse moyens pour les 10 rapports SAP les plus utilis√©s. 
                Il est essentiel pour identifier les rapports lents qui pourraient n√©cessiter une optimisation, 
                am√©liorant ainsi l'exp√©rience utilisateur et l'efficacit√© des processus m√©tier.
                """)
            if 'REPORT' in df_hitlist.columns and 'RESPTI' in df_hitlist.columns and df_hitlist['RESPTI'].sum() > 0:
                df_hitlist['RESPTI'] = pd.to_numeric(df_hitlist['RESPTI'], errors='coerce').fillna(0).astype(float)
                top_reports_resp = df_hitlist.groupby('REPORT', as_index=False)['RESPTI'].mean().nlargest(10, 'RESPTI')
                
                if not top_reports_resp.empty and top_reports_resp['RESPTI'].sum() > 0:
                    fig_reports_resp = px.bar(top_reports_resp, x='REPORT', y='RESPTI',
                                            title="Temps de R√©ponse Moyen (ms) par Rapport (Top 10)",
                                            labels={'REPORT': 'Rapport SAP', 'RESPTI': 'Temps de R√©ponse Moyen (ms)'},
                                            color='RESPTI', color_continuous_scale=px.colors.sequential.Bluyl)
                    st.plotly_chart(fig_reports_resp, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour le Temps de R√©ponse par Rapport apr√®s filtrage.")
            else:
                st.info("Colonnes 'REPORT' ou 'RESPTI' manquantes ou RESPTI total est z√©ro/vide apr√®s filtrage.")
            
            st.subheader("Corr√©lation Temps de R√©ponse (RESPTI) et Temps CPU (CPUTI) - Scatter Plot")
            st.markdown("""
                Ce nuage de points visualise la relation entre le temps de r√©ponse global d'une transaction et le temps CPU qu'elle consomme. 
                Une forte corr√©lation indique que le CPU est un facteur limitant la performance. 
                Les points aberrants (haut temps de r√©ponse, faible CPU ou vice-versa) peuvent signaler des goulots d'√©tranglement 
                li√©s √† la base de donn√©es, au r√©seau, ou √† des probl√®mes d'attente.
                """)
            if 'RESPTI' in df_hitlist.columns and 'CPUTI' in df_hitlist.columns:
                df_hitlist_scatter = df_hitlist[['RESPTI', 'CPUTI']].dropna()
                if not df_hitlist_scatter.empty:
                    df_hitlist_scatter['RESPTI'] = pd.to_numeric(df_hitlist_scatter['RESPTI'], errors='coerce').fillna(0).astype(float)
                    df_hitlist_scatter['CPUTI'] = pd.to_numeric(df_hitlist_scatter['CPUTI'], errors='coerce').fillna(0).astype(float)

                    if df_hitlist_scatter['RESPTI'].nunique() > 1 and df_hitlist_scatter['CPUTI'].nunique() > 1:
                        fig_resp_cpu_scatter = px.scatter(df_hitlist_scatter.sample(min(5000, len(df_hitlist_scatter)), random_state=42), # Sample for performance
                                                        x='CPUTI', y='RESPTI',
                                                        title="Corr√©lation Temps de R√©ponse vs. Temps CPU",
                                                        labels={'CPUTI': 'Temps CPU (ms)', 'RESPTI': 'Temps de R√©ponse (ms)'},
                                                        opacity=0.6,
                                                        hover_data={'CPUTI': True, 'RESPTI': True})
                        st.plotly_chart(fig_resp_cpu_scatter, use_container_width=True)
                    else:
                        st.info("Les colonnes 'RESPTI' ou 'CPUTI' ne contiennent pas suffisamment de variation pour cr√©er un Scatter Plot significatif apr√®s filtrage.")
                else:
                    st.info("Pas de donn√©es valides pour la corr√©lation Temps de R√©ponse et Temps CPU apr√®s filtrage.")
            else:
                st.info("Colonnes 'RESPTI' ou 'CPUTI' manquantes dans 'Hitlist DB'.")

            st.subheader("Temps d'Attente en File (QUEUETI) par Rapport - Top 10")
            st.markdown("""
                Ce graphique identifie les rapports associ√©s aux temps d'attente en file (QUEUETI) les plus √©lev√©s. 
                Des temps d'attente √©lev√©s indiquent des goulots d'√©tranglement dans le syst√®me, souvent li√©s √† des ressources insuffisantes 
                (processus de travail, base de donn√©es) ou √† un grand nombre de requ√™tes simultan√©es.
                """)
            if 'REPORT' in df_hitlist.columns and 'QUEUETI' in df_hitlist.columns and df_hitlist['QUEUETI'].sum() > 0:
                df_hitlist['QUEUETI'] = pd.to_numeric(df_hitlist['QUEUETI'], errors='coerce').fillna(0).astype(float)
                top_reports_queue = df_hitlist.groupby('REPORT', as_index=False)['QUEUETI'].mean().nlargest(10, 'QUEUETI')
                if not top_reports_queue.empty and top_reports_queue['QUEUETI'].sum() > 0:
                    fig_reports_queue = px.bar(top_reports_queue, x='REPORT', y='QUEUETI',
                                            title="Temps d'Attente en File (QUEUETI) Moyen par Rapport (Top 10)",
                                            labels={'REPORT': 'Rapport SAP', 'QUEUETI': "Temps d'Attente en File (ms)"},
                                            color='QUEUETI', color_continuous_scale=px.colors.sequential.Greens)
                    st.plotly_chart(fig_reports_queue, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Temps d'Attente en File par Rapport apr√®s filtrage.")
            else:
                st.info("Colonnes 'REPORT' ou 'QUEUETI' manquantes ou QUEUETI total est z√©ro/vide apr√®s filtrage.")
            
            st.subheader("Distribution des Appels Base de Donn√©es (DBCALLS)")
            st.markdown("""
                Ce graphique montre la distribution des appels de base de donn√©es (DBCALLS), ce qui est un indicateur cl√© de l'activit√© du syst√®me. 
                Des pics anormaux ou une distribution non uniforme peuvent signaler des requ√™tes inefficaces ou des probl√®mes de performance de la base de donn√©es.
                """)
            if 'DBCALLS' in df_hitlist.columns and df_hitlist['DBCALLS'].sum() > 0:
                df_hitlist['DBCALLS'] = pd.to_numeric(df_hitlist['DBCALLS'], errors='coerce').fillna(0).astype(float)
                if df_hitlist['DBCALLS'].nunique() > 1:
                    fig_dbcalls_dist = ff.create_distplot([df_hitlist['DBCALLS'].dropna()], ['DBCALLS'], show_rug=False, show_hist=False)
                    fig_dbcalls_dist.update_layout(title_text="Distribution des Appels Base de Donn√©es (DBCALLS)", xaxis_title='Nombre d\'Appels DB', yaxis_title='Densit√©')
                    fig_dbcalls_dist.data[0].line.color = 'darkblue'
                    st.plotly_chart(fig_dbcalls_dist, use_container_width=True)
                else:
                    st.info("La colonne 'DBCALLS' contient des valeurs uniques ou est vide apr√®s filtrage, impossible de cr√©er une courbe de densit√©.")
            else:
                st.info("Colonne 'DBCALLS' manquante ou total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Aper√ßu des Donn√©es Hitlist DB Filtr√©es")
            # TASKTYPE removal: Ensure TASKTYPE is not in this list
            columns_to_display_hitlist = [col for col in df_hitlist.columns if col not in ['TASKTYPE', 'FULL_DATETIME']]
            st.dataframe(df_hitlist[columns_to_display_hitlist].head())
        else:
            st.warning("Donn√©es Hitlist DB non disponibles ou filtr√©es √† vide.")

    elif st.session_state.current_section == "Performance des Processus de Travail":
        # --- Onglet 5: Performance des Processus de Travail (AL_GET_PERFORMANCE_final_cleaned_clean.xlsx) ---
        st.header("üöÄ Performance des Processus de Travail (Work Processes)")
        df_perf = dfs['performance'].copy()
        if selected_wp_types:
            df_perf = df_perf[df_perf['WP_TYP'].isin(selected_wp_types)]

        if not df_perf.empty:
            st.subheader("Temps CPU Moyen par Type de Processus de Travail (WP_TYP)")
            st.markdown("""
                Ce graphique compare la consommation moyenne de temps CPU par diff√©rents types de processus de travail (par exemple, dialogue, batch, spool). 
                Il permet de cibler l'optimisation des processus les plus gourmands en CPU et d'assurer une r√©partition √©quilibr√©e des ressources.
                """)
            if 'WP_TYP' in df_perf.columns and 'WP_CPU_SECONDS' in df_perf.columns and df_perf['WP_CPU_SECONDS'].sum() > 0:
                df_perf['WP_CPU_SECONDS'] = pd.to_numeric(df_perf['WP_CPU_SECONDS'], errors='coerce').fillna(0).astype(float)
                avg_cpu_by_wp_type = df_perf.groupby('WP_TYP', as_index=False)['WP_CPU_SECONDS'].mean().sort_values(by='WP_CPU_SECONDS', ascending=False)
                
                if not avg_cpu_by_wp_type.empty and avg_cpu_by_wp_type['WP_CPU_SECONDS'].sum() > 0:
                    fig_cpu_wp_type = px.bar(avg_cpu_by_wp_type, x='WP_TYP', y='WP_CPU_SECONDS',
                                            title="Temps CPU Moyen (secondes) par Type de Processus de Travail",
                                            labels={'WP_TYP': 'Type de Processus de Travail', 'WP_CPU_SECONDS': 'Temps CPU Moyen (s)'},
                                            color='WP_CPU_SECONDS', color_continuous_scale=px.colors.sequential.Cividis)
                    st.plotly_chart(fig_cpu_wp_type, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour le Temps CPU Moyen par Type de Processus de Travail apr√®s filtrage.")
            else:
                st.info("Colonnes 'WP_TYP' ou 'WP_CPU_SECONDS' manquantes ou WP_CPU_SECONDS total est z√©ro/vide.")

            st.subheader("Distribution des Temps d'Attente (WP_IWAIT)")
            st.markdown("""
                Ce graphique pr√©sente la distribution des temps d'attente (WP_IWAIT) pour les processus de travail. 
                Des temps d'attente √©lev√©s peuvent indiquer des goulots d'√©tranglement tels que la contention des ressources, 
                les blocages de base de donn√©es ou la lenteur des op√©rations d'E/S, n√©cessitant une investigation approfondie.
                """)
            if 'WP_IWAIT' in df_perf.columns and df_perf['WP_IWAIT'].sum() > 0:
                df_perf['WP_IWAIT'] = pd.to_numeric(df_perf['WP_IWAIT'], errors='coerce').fillna(0).astype(float)
                if df_perf['WP_IWAIT'].nunique() > 1:
                    fig_iwait_dist = ff.create_distplot([df_perf['WP_IWAIT'].dropna()], ['WP_IWAIT'], show_rug=False, show_hist=False)
                    fig_iwait_dist.update_layout(title_text="Distribution des Temps d'Attente (WP_IWAIT)", xaxis_title="Temps d'Attente (ms)", yaxis_title='Densit√©')
                    fig_iwait_dist.data[0].line.color = 'red'
                    st.plotly_chart(fig_iwait_dist, use_container_width=True)
                else:
                    st.info("La colonne 'WP_IWAIT' contient des valeurs uniques ou est vide apr√®s filtrage, impossible de cr√©er une courbe de densit√©.")
            else:
                st.info("Colonne 'WP_IWAIT' manquante ou total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Statut des Processus de Travail (WP_STATUS)")
            st.markdown("""
                Ce graphique √† barres montre la r√©partition des processus de travail par leur statut (par exemple, en cours, en attente, stopp√©). 
                Une grande proportion de processus en attente ou stopp√©s peut indiquer des probl√®mes de configuration, 
                des blocages ou des insuffisances de ressources qui affectent la disponibilit√© et la performance.
                """)
            if 'WP_STATUS' in df_perf.columns and not df_perf['WP_STATUS'].isnull().all():
                status_counts = df_perf['WP_STATUS'].value_counts().reset_index()
                status_counts.columns = ['WP_STATUS', 'Count']
                if not status_counts.empty and status_counts['Count'].sum() > 0:
                    fig_wp_status = px.bar(status_counts, x='WP_STATUS', y='Count',
                                        title="R√©partition par Statut des Processus de Travail",
                                        labels={'WP_STATUS': 'Statut du Processus', 'Count': 'Nombre'},
                                        color='Count', color_continuous_scale=px.colors.sequential.Aggrnyl)
                    st.plotly_chart(fig_wp_status, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Statuts des Processus de Travail apr√®s filtrage.")
            else:
                st.info("Colonne 'WP_STATUS' manquante ou vide apr√®s filtrage.")

            st.subheader("Aper√ßu des Donn√©es Performance Filtr√©es")
            st.dataframe(df_perf.head())
        else:
            st.warning("Donn√©es de performance des processus de travail non disponibles ou filtr√©es √† vide.")

    elif st.session_state.current_section == "R√©sum√© des Traces de Performance SQL":
        # --- Onglet 6: R√©sum√© des Traces de Performance SQL (performance_trace_summary_final_cleaned_clean.xlsx) ---
        st.header("‚ö° R√©sum√© des Traces de Performance SQL")
        df_sql = dfs['sql_trace_summary'].copy()

        if not df_sql.empty:
            st.subheader("Top 10 des Statements SQL par Temps d'Ex√©cution (EXECTIME)")
            st.markdown("""
                Ce graphique identifie les 10 requ√™tes SQL les plus longues en termes de temps d'ex√©cution. 
                L'optimisation de ces requ√™tes est souvent le moyen le plus efficace d'am√©liorer radicalement la performance globale de la base de donn√©es.
                """)
            if 'SQLSTATEM' in df_sql.columns and 'EXECTIME' in df_sql.columns and df_sql['EXECTIME'].sum() > 0:
                df_sql['EXECTIME'] = pd.to_numeric(df_sql['EXECTIME'], errors='coerce').fillna(0).astype(float)
                top_sql_exec_time = df_sql.groupby('SQLSTATEM', as_index=False)['EXECTIME'].sum().nlargest(10, 'EXECTIME')
                
                if not top_sql_exec_time.empty and top_sql_exec_time['EXECTIME'].sum() > 0:
                    fig_sql_exec_time = px.bar(top_sql_exec_time, x='SQLSTATEM', y='EXECTIME',
                                            title="Top 10 Statements SQL par Temps d'Ex√©cution Total (ms)",
                                            labels={'SQLSTATEM': 'Statement SQL', 'EXECTIME': "Temps d'Ex√©cution (ms)"},
                                            color='EXECTIME', color_continuous_scale=px.colors.sequential.Oranges)
                    st.plotly_chart(fig_sql_exec_time, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Top 10 Statements SQL par Temps d'Ex√©cution apr√®s filtrage.")
            else:
                st.info("Colonnes 'SQLSTATEM' ou 'EXECTIME' manquantes ou EXECTIME total est z√©ro/vide.")

            st.subheader("Top 10 des Statements SQL par Nombre Total d'Ex√©cutions (TOTALEXEC)")
            st.markdown("""
                Ce graphique met en lumi√®re les 10 requ√™tes SQL les plus fr√©quemment ex√©cut√©es. 
                M√™me si une requ√™te n'est pas la plus lente individuellement, son ex√©cution fr√©quente peut en faire un goulot d'√©tranglement majeur. 
                L'optimisation de ces requ√™tes peut avoir un impact significatif sur la performance globale.
                """)
            if 'SQLSTATEM' in df_sql.columns and 'TOTALEXEC' in df_sql.columns and df_sql['TOTALEXEC'].sum() > 0:
                df_sql['TOTALEXEC'] = pd.to_numeric(df_sql['TOTALEXEC'], errors='coerce').fillna(0).astype(float)
                top_sql_total_exec = df_sql.groupby('SQLSTATEM', as_index=False)['TOTALEXEC'].sum().nlargest(10, 'TOTALEXEC')
                
                if not top_sql_total_exec.empty and top_sql_total_exec['TOTALEXEC'].sum() > 0:
                    fig_sql_total_exec = px.bar(top_sql_total_exec, x='SQLSTATEM', y='TOTALEXEC',
                                            title="Top 10 Statements SQL par Nombre Total d'Ex√©cutions",
                                            labels={'SQLSTATEM': 'Statement SQL', 'TOTALEXEC': "Nombre Total d'Ex√©cutions"},
                                            color='TOTALEXEC', color_continuous_scale=px.colors.sequential.Blues)
                    st.plotly_chart(fig_sql_total_exec, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour les Top 10 Statements SQL par Nombre Total d'Ex√©cutions apr√®s filtrage.")
            else:
                st.info("Colonnes 'SQLSTATEM' ou 'TOTALEXEC' manquantes ou TOTALEXEC total est z√©ro/vide.")

            st.subheader("Distribution du Temps par Ex√©cution (TIMEPEREXE)")
            st.markdown("""
                Cette courbe de densit√© visualise la distribution du temps moyen pass√© par chaque ex√©cution de requ√™te SQL. 
                Elle aide √† identifier si les requ√™tes sont g√©n√©ralement rapides avec quelques exceptions, 
                ou si elles sont globalement lentes, n√©cessitant une approche diff√©rente d'optimisation.
                """)
            if 'TIMEPEREXE' in df_sql.columns and df_sql['TIMEPEREXE'].sum() > 0:
                df_sql['TIMEPEREXE'] = pd.to_numeric(df_sql['TIMEPEREXE'], errors='coerce').fillna(0).astype(float)
                if df_sql['TIMEPEREXE'].nunique() > 1:
                    fig_timeperexe_dist = ff.create_distplot([df_sql['TIMEPEREXE'].dropna()], ['TIMEPEREXE'], show_rug=False, show_hist=False)
                    fig_timeperexe_dist.update_layout(title_text="Distribution du Temps par Ex√©cution (TIMEPEREXE)", xaxis_title="Temps par Ex√©cution (ms)", yaxis_title='Densit√©')
                    fig_timeperexe_dist.data[0].line.color = 'darkgreen'
                    st.plotly_chart(fig_timeperexe_dist, use_container_width=True)
                else:
                    st.info("La colonne 'TIMEPEREXE' contient des valeurs uniques ou est vide apr√®s filtrage, impossible de cr√©er une courbe de densit√©.")
            else:
                st.info("Colonne 'TIMEPEREXE' manquante ou total est z√©ro/vide apr√®s filtrage.")

            st.subheader("Aper√ßu des Donn√©es SQL Trace Summary Filtr√©es")
            st.dataframe(df_sql.head())
        else:
            st.warning("Donn√©es de r√©sum√© des traces SQL non disponibles ou filtr√©es √† vide.")

    elif st.session_state.current_section == "Analyse des Utilisateurs":
        # --- Onglet 7: Analyse des Utilisateurs (usr02_data.xlsx) ---
        st.header("üë• Analyse des Utilisateurs SAP (USR02)")
        df_usr02 = dfs['usr02'].copy()

        if not df_usr02.empty:
            st.subheader("Nombre d'Utilisateurs par Type (USTYP)")
            st.markdown("""
                Ce graphique en camembert pr√©sente la r√©partition des utilisateurs par leur type (par exemple, dialogue, service, syst√®me). 
                Il est utile pour la conformit√© et la s√©curit√©, permettant d'identifier les proportions de diff√©rents types de comptes et de d√©tecter les anomalies.
                """)
            if 'USTYP' in df_usr02.columns and not df_usr02['USTYP'].isnull().all():
                user_type_counts = df_usr02['USTYP'].value_counts().reset_index()
                user_type_counts.columns = ['USTYP', 'Count']
                if not user_type_counts.empty and user_type_counts['Count'].sum() > 0:
                    fig_user_type = px.pie(user_type_counts, values='Count', names='USTYP',
                                        title="R√©partition des Utilisateurs par Type (USTYP)",
                                        hole=0.3)
                    fig_user_type.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig_user_type, use_container_width=True)
                else:
                    st.info("Pas de donn√©es valides pour le Nombre d'Utilisateurs par Type apr√®s filtrage.")
            else:
                st.info("Colonne 'USTYP' manquante ou vide apr√®s filtrage.")

            st.subheader("Distribution des Derni√®res Connexions (GLTGB_DATE)")
            st.markdown("""
                Cet histogramme visualise la fr√©quence des derni√®res connexions des utilisateurs au fil du temps. 
                Il peut aider √† identifier les comptes inactifs qui devraient √™tre examin√©s pour des raisons de s√©curit√© ou de conformit√©, 
                et √† comprendre les patterns de connexion.
                """)
            if 'GLTGB_DATE' in df_usr02.columns and not df_usr02['GLTGB_DATE'].isnull().all():
                # Filter out dates before a reasonable start, e.g., 2000-01-01 if there are many '00000000'
                df_usr02_dates = df_usr02.dropna(subset=['GLTGB_DATE'])
                if not df_usr02_dates.empty and len(df_usr02_dates['GLTGB_DATE'].unique()) > 1:
                    fig_last_logon = px.histogram(df_usr02_dates, x='GLTGB_DATE',
                                                title="Distribution des Derni√®res Connexions des Utilisateurs",
                                                labels={'GLTGB_DATE': 'Date de Derni√®re Connexion'},
                                                nbins=30, # Adjust number of bins as needed
                                                color_discrete_sequence=['cadetblue'])
                    st.plotly_chart(fig_last_logon, use_container_width=True)
                else:
                    st.info("La colonne 'GLTGB_DATE' contient des valeurs uniques ou est vide apr√®s filtrage, impossible de cr√©er un histogramme.")
            else:
                st.info("Colonne 'GLTGB_DATE' manquante ou vide apr√®s filtrage.")

            st.subheader("Aper√ßu des Donn√©es Utilisateurs Filtr√©es")
            st.dataframe(df_usr02.head())
        else:
            st.warning("Donn√©es utilisateurs (USR02) non disponibles ou filtr√©es √† vide.")

    elif st.session_state.current_section == "D√©tection d'Anomalies":
        # --- Onglet 8: D√©tection d'Anomalies (sur Hitlist DB) ---
        st.header("üö® D√©tection d'Anomalies sur le Temps de R√©ponse (Hitlist DB)")
        st.markdown("""
            Cette section utilise une m√©thode simple de d√©tection d'anomalies bas√©e sur l'√©cart type pour identifier les temps de r√©ponse exceptionnellement √©lev√©s.
            Les points marqu√©s comme 'Anomalie' sont ceux qui d√©passent un seuil d√©fini (moyenne + 3 * √©cart-type), indiquant des performances potentiellement probl√©matiques.
            """)
        
        df_anomalies = dfs['hitlist_db'].copy()
        if not df_anomalies.empty and 'RESPTI' in df_anomalies.columns and 'FULL_DATETIME' in df_anomalies.columns:
            # Ensure columns are numeric and datetime
            df_anomalies['RESPTI'] = pd.to_numeric(df_anomalies['RESPTI'], errors='coerce').fillna(0).astype(float)
            df_anomalies['FULL_DATETIME'] = pd.to_datetime(df_anomalies['FULL_DATETIME'], errors='coerce')
            
            df_anomalies_clean = df_anomalies.dropna(subset=['RESPTI', 'FULL_DATETIME']).copy()

            if not df_anomalies_clean.empty and df_anomalies_clean['RESPTI'].nunique() > 1:
                # Calculer la moyenne mobile et l'√©cart type mobile
                window = 50 # Fen√™tre pour la moyenne mobile et l'√©cart type
                df_anomalies_clean['Mean_RESPTI'] = df_anomalies_clean['RESPTI'].rolling(window=window, min_periods=1).mean()
                df_anomalies_clean['Std_RESPTI'] = df_anomalies_clean['RESPTI'].rolling(window=window, min_periods=1).std()

                # D√©finir le seuil pour l'anomalie (ex: 3 √©carts types au-dessus de la moyenne)
                n_std = st.slider("Facteur d'√âcart Type pour les Anomalies", min_value=1.0, max_value=5.0, value=3.0, step=0.1)
                df_anomalies_clean['Upper_Bound'] = df_anomalies_clean['Mean_RESPTI'] + n_std * df_anomalies_clean['Std_RESPTI']
                
                # Identifier les anomalies
                df_anomalies_clean['Anomaly'] = df_anomalies_clean['RESPTI'] > df_anomalies_clean['Upper_Bound']

                # Visualisation
                fig_anomalies = px.line(df_anomalies_clean, x='FULL_DATETIME', y='RESPTI',
                                        title="D√©tection d'Anomalies dans le Temps de R√©ponse (RESPTI)",
                                        labels={'FULL_DATETIME': 'Date et Heure', 'RESPTI': 'Temps de R√©ponse (ms)'})
                
                # Ajouter la moyenne mobile et les bornes sup√©rieures
                fig_anomalies.add_scatter(x=df_anomalies_clean['FULL_DATETIME'], y=df_anomalies_clean['Mean_RESPTI'], mode='lines', name=f'Moyenne Mobile ({window} pts)', line=dict(color='orange', dash='dash'))
                fig_anomalies.add_scatter(x=df_anomalies_clean['FULL_DATETIME'], y=df_anomalies_clean['Upper_Bound'], mode='lines', name=f'Seuil Anomalie (+{n_std} StdDev)', line=dict(color='red', dash='dot'))

                # Mettre en √©vidence les anomalies
                anomalies_points = df_anomalies_clean[df_anomalies_clean['Anomaly']]
                if not anomalies_points.empty:
                    fig_anomalies.add_scatter(x=anomalies_points['FULL_DATETIME'], y=anomalies_points['RESPTI'], mode='markers', name='Anomalie',
                                            marker=dict(color='red', size=8, symbol='x'))
                
                st.plotly_chart(fig_anomalies, use_container_width=True)

                st.subheader("D√©tails des Anomalies D√©tect√©es")
                if not anomalies_points.empty:
                    st.dataframe(anomalies_points[['FULL_DATETIME', 'RESPTI', 'Mean_RESPTI', 'Upper_Bound']].sort_values(by='RESPTI', ascending=False))
                else:
                    st.info("Aucune anomalie d√©tect√©e avec les param√®tres actuels.")
            else:
                st.info("La colonne 'RESPTI' ne contient pas suffisamment de variation pour la d√©tection d'anomalies, ou les donn√©es sont vides apr√®s nettoyage.")
        else:
            st.warning("Donn√©es Hitlist DB non disponibles ou colonnes requises (RESPTI, FULL_DATETIME) manquantes pour la d√©tection d'anomalies.")

    elif st.session_state.current_section == "Pr√©diction de Performance (ML)":
        # --- Onglet 9: Pr√©diction de Performance (ML) ---
        st.header("ü§ñ Pr√©diction de Performance (ML)")
        st.markdown("""
            Cette section utilise un mod√®le de Machine Learning (For√™t Al√©atoire) pour pr√©dire le temps de r√©ponse (RESPTI) 
            bas√© sur d'autres m√©triques. Le mod√®le est entra√Æn√© sur les donn√©es 'Hitlist DB'.
            """)

        df_ml = dfs['hitlist_db'].copy()

        if not df_ml.empty:
            st.subheader("Configuration et Entra√Ænement du Mod√®le")
            
            # S√©lection de la colonne cible pour la pr√©diction
            available_target_cols = ['RESPTI', 'PROCTI', 'CPUTI', 'DBCALLS'] # Add other relevant numeric columns if applicable
            target_ml_column = st.selectbox("S√©lectionner la colonne cible pour la pr√©diction (Y)", available_target_cols, index=0)

            # S√©lection des colonnes de features
            # Exclure la cible, les identifiants et les colonnes de date/heure complexes ou non num√©riques
            all_ml_cols = [col for col in df_ml.columns if pd.api.types.is_numeric_dtype(df_ml[col]) or pd.api.types.is_string_dtype(df_ml[col])]
            
            # Removed irrelevant features and potentially problematic ones like 'ENDTIME', 'FULL_DATETIME'
            exclude_features = [target_ml_column, 'FULL_DATETIME', 'ENDDATE', 'ENDTIME', 'ENDTIME_STR', 'WPID', 'ACCOUNT', 'REPORT', 'ROLLKEY', 'PRIVMODE', 'WPRESTART']
            # Also exclude any columns that might be entirely NaN or have very few unique values
            final_features = [col for col in all_ml_cols if col not in exclude_features and df_ml[col].nunique() > 1]
            
            if not final_features:
                st.warning("Aucune colonne num√©rique valide n'est disponible pour les features apr√®s exclusion. Le mod√®le ne peut pas √™tre entra√Æn√©.")
            else:
                selected_features = st.multiselect("S√©lectionner les features (X) pour la pr√©diction", final_features, default=final_features[:min(len(final_features), 5)]) # Select first 5 by default

                if target_ml_column not in df_ml.columns or df_ml[target_ml_column].isnull().all():
                    st.error(f"La colonne cible '{target_ml_column}' est manquante ou vide dans les donn√©es.")
                elif not selected_features:
                    st.error("Veuillez s√©lectionner au moins une feature pour l'entra√Ænement du mod√®le.")
                else:
                    # Pr√©paration des donn√©es
                    X = df_ml[selected_features]
                    y = df_ml[target_ml_column]

                    # G√©rer les valeurs non num√©riques (ex: strings) pour l'encodage One-Hot
                    # G√©rer les valeurs manquantes avant l'entra√Ænement
                    numeric_features = X.select_dtypes(include=np.number).columns
                    categorical_features = X.select_dtypes(include='object').columns

                    numeric_transformer = Pipeline(steps=[
                        ('imputer', SimpleImputer(strategy='mean'))
                    ])

                    categorical_transformer = Pipeline(steps=[
                        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                        ('onehot', OneHotEncoder(handle_unknown='ignore'))
                    ])

                    preprocessor = ColumnTransformer(
                        transformers=[
                            ('num', numeric_transformer, numeric_features),
                            ('cat', categorical_transformer, categorical_features)
                        ])

                    # Cr√©ation du pipeline du mod√®le
                    model = Pipeline(steps=[('preprocessor', preprocessor),
                                            ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])

                    # Division des donn√©es
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                    st.write("Entra√Ænement du mod√®le en cours...")
                    try:
                        model.fit(X_train, y_train)
                        st.success("Mod√®le entra√Æn√© avec succ√®s!")

                        # √âvaluation du mod√®le
                        y_pred = model.predict(X_test)
                        r2 = r2_score(y_test, y_pred)
                        mae = mean_absolute_error(y_test, y_pred)

                        st.subheader("√âvaluation du Mod√®le")
                        st.write(f"**Coefficient de D√©termination (R¬≤):** {r2:.2f}")
                        st.write(f"**Erreur Absolue Moyenne (MAE):** {mae:.2f}")

                        st.markdown("""
                            * **R¬≤ (Coefficient de D√©termination)**: Mesure la proportion de la variance de la variable d√©pendante qui est pr√©visible √† partir des variables ind√©pendantes. Un R¬≤ de 1.0 indique que le mod√®le explique 100% de la variance, 0.0 indique qu'il n'explique rien.
                            * **MAE (Erreur Absolue Moyenne)**: Repr√©sente la moyenne des erreurs absolues entre les pr√©dictions et les valeurs r√©elles. C'est une mesure de l'erreur moyenne en valeur absolue.
                            """)

                        # Importance des features
                        st.subheader("Importance des Features")
                        if hasattr(model.named_steps['regressor'], 'feature_importances_'):
                            # Get feature names after one-hot encoding
                            ohe_feature_names = model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)
                            all_processed_features = list(numeric_features) + list(ohe_feature_names)
                            
                            feature_importances = pd.Series(model.named_steps['regressor'].feature_importances_, index=all_processed_features)
                            
                            # Filter out features with 0 importance if they are from one-hot encoding of categories not present in train
                            feature_importances = feature_importances[feature_importances > 0].sort_values(ascending=False)
                            
                            if not feature_importances.empty:
                                fig_importance = px.bar(feature_importances.head(10), # Top 10 features
                                                        x=feature_importances.head(10).index, y=feature_importances.head(10).values,
                                                        title="Top 10 Importances des Features",
                                                        labels={'x': 'Feature', 'y': 'Importance'},
                                                        color=feature_importances.head(10).values, color_continuous_scale=px.colors.sequential.Viridis)
                                st.plotly_chart(fig_importance, use_container_width=True)
                            else:
                                st.info("Aucune feature n'a d'importance significative (toutes sont nulles ou tr√®s faibles).")
                        else:
                            st.info("Le mod√®le ne supporte pas l'extraction de l'importance des features.")

                        # Visualisation des pr√©dictions vs. valeurs r√©elles
                        st.subheader("Pr√©dictions vs. Valeurs R√©elles")
                        df_results = pd.DataFrame({'Valeurs R√©elles': y_test, 'Pr√©dictions': y_pred})
                        fig_pred = px.scatter(df_results.sample(min(500, len(df_results)), random_state=42), # √âchantillon pour la visibilit√©
                                            x='Valeurs R√©elles', y='Pr√©dictions',
                                            title=f"Pr√©dictions vs. Valeurs R√©elles pour {target_ml_column}",
                                            labels={'Valeurs R√©elles': f'Valeurs R√©elles de {target_ml_column}', 'Pr√©dictions': f'Pr√©dictions de {target_ml_column}'},
                                            trendline='ols', # Ligne de r√©gression lin√©aire
                                            opacity=0.6)
                        fig_pred.update_traces(marker_size=5)
                        st.plotly_chart(fig_pred, use_container_width=True)

                        st.write("""
                            Un bon mod√®le aura des points group√©s pr√®s de la ligne diagonale (o√π les pr√©dictions √©galent les valeurs r√©elles).
                            """)
                    except Exception as e:
                        st.error(f"Erreur lors de l'entra√Ænement ou de l'√©valuation du mod√®le : {e}")

# --- T√©l√©chargement du script ---
st.sidebar.markdown("---")
st.sidebar.subheader("T√©l√©charger le Script")
script_code = io.StringIO()
with open(__file__, "r", encoding="utf-8") as f:
    script_code.write(f.read())
st.sidebar.download_button(
    label="T√©l√©charger le Script",
    data=script_code.getvalue(),
    file_name="TTEST_dashboard_sap_corrected.py",
    mime="text/x-python"
)
