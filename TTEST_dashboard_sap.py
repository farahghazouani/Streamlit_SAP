elif st.session_state.current_section == "Pr√©diction de Performance (ML)":
    st.header("üîÆ Pr√©diction de Performance (ML)")
    st.markdown("""
        Utilisez cette section pour entra√Æner un mod√®le de Machine Learning et pr√©dire une m√©trique de performance.
        Le mod√®le utilise les autres colonnes comme caract√©ristiques (features) pour apprendre √† pr√©dire la colonne cible.
        """)

    # S√©lection de la source de donn√©es
    ml_source_data_key = st.selectbox(
        "S√©lectionner la source de donn√©es pour la ML :",
        options=["hitlist_db", "memory", "times", "usertcode", "performance", "sql_trace_summary"],
        index=0 # Default to hitlist_db
    )

    df_ml = dfs[ml_source_data_key].copy()

    if df_ml.empty:
        st.warning(f"La source de donn√©es '{ml_source_data_key}' est vide ou n'a pas pu √™tre charg√©e. Impossible de proc√©der √† la pr√©diction.")
    else:
        st.subheader("Pr√©paration des Donn√©es pour la Pr√©diction")

        # S√©lection de la colonne cible pour la pr√©diction
        numeric_cols_for_target = df_ml.select_dtypes(include=np.number).columns.tolist()
        if not numeric_cols_for_target:
            st.error(f"La source de donn√©es '{ml_source_data_key}' ne contient aucune colonne num√©rique pour la pr√©diction. Veuillez choisir une autre source.")
        else:
            target_ml_column = st.selectbox(
                "S√©lectionner la colonne cible √† pr√©dire (doit √™tre num√©rique) :",
                options=numeric_cols_for_target
            )

            # Pr√©paration des caract√©ristiques (features) et de la cible
            X = df_ml.drop(columns=[target_ml_column], errors='ignore')
            y = df_ml[target_ml_column]

            # Supprimer les colonnes avec trop de valeurs manquantes ou non num√©riques pour X
            # (Exclure la colonne cible qui est d√©j√† g√©r√©e)
            initial_columns = X.columns.tolist()
            X = X.dropna(axis=1, how='all') # Supprime les colonnes enti√®rement NaN
            X = X.select_dtypes(exclude=['datetime64[ns]']) # Exclure les colonnes datetime qui ne sont pas directement utilisables

            # Supprimer les colonnes avec une seule valeur unique (variance nulle)
            columns_to_drop_single_value = [col for col in X.columns if X[col].nunique() == 1]
            if columns_to_drop_single_value:
                X = X.drop(columns=columns_to_drop_single_value)
                st.info(f"Colonnes supprim√©es car elles ne contenaient qu'une seule valeur unique : {', '.join(columns_to_drop_single_value)}")

            # S'assurer que les jeux de donn√©es ne sont pas vides apr√®s le nettoyage
            if X.empty or y.empty:
                st.error("Les donn√©es nettoy√©es pour la pr√©diction sont vides. Veuillez v√©rifier votre s√©lection ou vos donn√©es brutes.")
            else:
                st.write(f"Nombre de caract√©ristiques utilis√©es : {X.shape[1]}")
                st.write(f"Premi√®res lignes des caract√©ristiques (X) :")
                st.dataframe(X.head())
                st.write(f"Premi√®res lignes de la cible (y) :")
                st.dataframe(y.head())

                # Division des donn√©es en ensembles d'entra√Ænement et de test
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                st.write(f"Taille de l'ensemble d'entra√Ænement : {len(X_train)} √©chantillons")
                st.write(f"Taille de l'ensemble de test : {len(X_test)} √©chantillons")

                st.subheader("Entra√Ænement et √âvaluation du Mod√®le")

                try:
                    # Identifier les colonnes num√©riques et cat√©gorielles apr√®s le nettoyage
                    numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()
                    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()

                    # Cr√©er les pipelines de pr√©traitement
                    numerical_transformer = Pipeline(steps=[
                        ('imputer', SimpleImputer(strategy='mean')),
                        ('scaler', StandardScaler())
                    ])

                    categorical_transformer = Pipeline(steps=[
                        ('imputer', SimpleImputer(strategy='most_frequent')),
                        ('onehot', OneHotEncoder(handle_unknown='ignore'))
                    ])

                    # Combiner les transformateurs avec ColumnTransformer
                    preprocessor = ColumnTransformer(
                        transformers=[
                            ('num', numerical_transformer, numerical_features),
                            ('cat', categorical_transformer, categorical_features)
                        ],
                        remainder='passthrough' # Garde les colonnes non sp√©cifi√©es
                    )

                    # D√©finir le mod√®le
                    model = RandomForestRegressor(n_estimators=100, random_state=42)

                    # Cr√©er le pipeline complet
                    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                                     ('regressor', model)])

                    # FIT THE MODEL PIPELINE ON THE TRAINING DATA
                    # C'EST LA LIGNE CRUCIALE √Ä AJOUTER OU V√âRIFIER
                    model_pipeline.fit(X_train, y_train)

                    # Faire des pr√©dictions
                    y_pred = model_pipeline.predict(X_test)

                    # √âvaluation du mod√®le
                    r2 = r2_score(y_test, y_pred)
                    mae = mean_absolute_error(y_test, y_pred)

                    st.write(f"**R¬≤ Score :** {r2:.4f}")
                    st.write(f"**Erreur Absolue Moyenne (MAE) :** {mae:.4f}")

                    st.markdown("""
                        * **R¬≤ Score :** Indique la proportion de la variance de la variable d√©pendante qui est pr√©dictible √† partir des variables ind√©pendantes. Un R¬≤ de 1.0 indique un ajustement parfait.
                        * **MAE (Mean Absolute Error) :** Repr√©sente la moyenne des erreurs absolues entre les pr√©dictions et les valeurs r√©elles. Une MAE plus faible indique un meilleur mod√®le.
                        """)

                    st.subheader("Importance des Caract√©ristiques")
                    # L'importance des features est obtenue √† partir du mod√®le RFR qui est l'√©tape 'regressor' du pipeline
                    # et qui a √©t√© entra√Æn√© apr√®s le pr√©traitement.
                    if hasattr(model_pipeline.named_steps['regressor'], 'feature_importances_'):
                        # R√©cup√©rer les noms des colonnes apr√®s pr√©traitement
                        preprocessor_fitted = model_pipeline.named_steps['preprocessor']
                        
                        # Noms des features num√©riques
                        numeric_feature_names = numerical_features
                        
                        # Noms des features cat√©gorielles apr√®s OneHotEncoding
                        # Assurez-vous que le OneHotEncoder est accessible et fit
                        try:
                            ohe_feature_names = preprocessor_fitted.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)
                        except Exception as e:
                            st.warning(f"Impossible de r√©cup√©rer les noms de features OneHotEncoded : {e}")
                            ohe_feature_names = [] # Fallback if get_feature_names_out fails


                        # Concat√©ner tous les noms de features transform√©es
                        all_feature_names = numerical_features + list(ohe_feature_names)
                        
                        # G√©rer les colonnes 'passthrough' si elles existent et ne sont pas num√©riques/cat√©goriques
                        # La logique 'remainder'='passthrough' est dans ColumnTransformer, mais ses noms de colonnes
                        # ne sont pas directement accessibles via get_feature_names_out() sans une complexit√© suppl√©mentaire.
                        # Pour ce cas, nous allons nous fier aux features_importances_ qui correspondent √† l'ordre de traitement.

                        importances = model_pipeline.named_steps['regressor'].feature_importances_

                        # Cr√©er un DataFrame pour l'importance des caract√©ristiques
                        # V√©rifier que le nombre d'importances correspond au nombre de features
                        if len(importances) == len(all_feature_names):
                            feature_importance_df = pd.DataFrame({
                                'Feature': all_feature_names,
                                'Importance': importances
                            }).sort_values(by='Importance', ascending=False)
                            st.dataframe(feature_importance_df)

                            fig_importance = px.bar(feature_importance_df.head(10),
                                                    x='Importance', y='Feature', orientation='h',
                                                    title="Top 10 Importance des Caract√©ristiques",
                                                    labels={'Importance': 'Score d\'Importance', 'Feature': 'Caract√©ristique'},
                                                    color='Importance', color_continuous_scale=px.colors.sequential.Greens)
                            st.plotly_chart(fig_importance, use_container_width=True)
                        else:
                            st.warning(f"Le nombre d'importances ({len(importances)}) ne correspond pas au nombre de caract√©ristiques ({len(all_feature_names)}) apr√®s pr√©traitement. L'affichage de l'importance des caract√©ristiques peut √™tre incorrect.")
                            st.info("Cela peut arriver si des colonnes ont √©t√© supprim√©es par le pr√©processeur ou si des types de colonnes inattendus sont pr√©sents.")
                            # Fallback: display importance with generic names if mismatch occurs
                            feature_importance_df = pd.DataFrame({
                                'Feature': [f'Feature_{i}' for i in range(len(importances))],
                                'Importance': importances
                            }).sort_values(by='Importance', ascending=False)
                            st.dataframe(feature_importance_df.head(10))
                    else:
                        st.info("Le mod√®le ne supporte pas l'acc√®s direct √† l'importance des caract√©ristiques.")

                    st.subheader("Visualisation des Pr√©dictions")
                    df_results = pd.DataFrame({'Valeurs R√©elles': y_test, 'Pr√©dictions': y_pred})
                    fig_pred = px.scatter(df_results.sample(min(500, len(df_results)), random_state=42), # √âchantillon pour la visibilit√©
                                        x='Valeurs R√©elles', y='Pr√©dictions',
                                        title=f"Pr√©dictions vs. Valeurs R√©elles pour {target_ml_column}",
                                        labels={'Valeurs R√©elles': f'Valeurs R√©elles de {target_ml_column}', 'Pr√©dictions': f'Pr√©dictions de {target_ml_column}'},
                                        trendline='ols', # Ligne de r√©gression lin√©aire
                                        opacity=0.6)
                    fig_pred.update_traces(marker_size=5)
                    st.plotly_chart(fig_pred, use_container_width=True)

                    st.write("""
                        Un bon mod√®le aura des points group√©s pr√®s de la ligne diagonale (o√π les pr√©dictions √©galent les valeurs r√©elles).
                        """)
                except Exception as e:
                    st.error(f"Erreur lors de l'entra√Ænement ou de l'√©valuation du mod√®le : {e}")

# --- T√©l√©chargement du script ---
st.sidebar.markdown("---")
st.sidebar.subheader("T√©l√©charger le Script")
script_code = io.StringIO()
with open(__file__, "r", encoding="utf-8") as f:
    script_code.write(f.read())
st.sidebar.download_button(
    label="T√©l√©charger TTEST_dashboard_sap.py",
    data=script_code.getvalue(),
    file_name="TTEST_dashboard_sap.py",
    mime="text/x-python"
)
